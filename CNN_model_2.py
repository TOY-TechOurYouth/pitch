# train_model.py
import pandas as pd
import numpy as np
import joblib
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, Flatten, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from collections import Counter
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay

# í•œê¸€ í°íŠ¸ ì„¤ì • (Windows í™˜ê²½)
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
X = joblib.load("files_for_train/features_175d.pkl")
y = joblib.load("files_for_train/labels_gender.pkl")
wav_ids = joblib.load("files_for_train/wav_ids.pkl")
sources = joblib.load("files_for_train/sources.pkl")  # ì¶”ê°€ëœ source ì •ë³´

X = np.array(X)
y = np.array(y)
wav_ids = np.array(wav_ids)
sources = np.array(sources)

# ë‹¤ìš´ìƒ˜í”Œë§
df = pd.DataFrame(X)
df['label'] = y
df['wav_id'] = wav_ids
df['source'] = sources

male_df = df[df['label'] == 'male']
female_df = df[df['label'] == 'female'].sample(n=len(male_df), random_state=42)
df_balanced = pd.concat([male_df, female_df]).sample(frac=1, random_state=42)

X_balanced = df_balanced.drop(columns=['label', 'wav_id', 'source']).values
y_balanced = df_balanced['label'].values
wav_ids_balanced = df_balanced['wav_id'].values
sources_balanced = df_balanced['source'].values

# ì„±ë³„ ë¶„í¬ ì¶œë ¥ ë° ì‹œê°í™”
gender_counts = Counter(y_balanced)
total = sum(gender_counts.values())
print("ğŸ“Š í•™ìŠµì— ì‚¬ìš©ëœ ì„±ë³„ ë¶„í¬:")
for gender, count in gender_counts.items():
    print(f"{gender}: {count}ëª… ({count / total * 100:.2f}%)")

plt.figure(figsize=(6, 6))
plt.pie(gender_counts.values(), labels=gender_counts.keys(), autopct='%1.1f%%', startangle=90)
plt.title("í•™ìŠµ ë°ì´í„° ì„±ë³„ ë¶„í¬")
plt.axis("equal")
plt.savefig("balanced_gender_distribution.png", dpi=300)
print("ğŸ–¼ï¸ ì„±ë³„ ë¶„í¬ ì°¨íŠ¸ saved as 'balanced_gender_distribution.png'")
plt.show()

# ì •ê·œí™” ë° ì €ì¥
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_balanced)
joblib.dump(scaler, "files_for_train/scaler.pkl")

# ë¼ë²¨ ì¸ì½”ë”© ë° One-hot
le = LabelEncoder()
y_encoded = le.fit_transform(y_balanced)
y_onehot = to_categorical(y_encoded)

# ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test, wav_train, wav_test, src_train, src_test = train_test_split(
    X_scaled, y_onehot, wav_ids_balanced, sources_balanced,
    test_size=0.2, random_state=42, stratify=y_encoded
)

print(f"\nğŸ“¦ ë°ì´í„° ë¶„í•  ê²°ê³¼:")
print(f"Train set: {X_train.shape[0]}ê°œ")
print(f"Test set : {X_test.shape[0]}ê°œ")

# ì…ë ¥ ì°¨ì› ì¶”ê°€
X_train = X_train[..., np.newaxis]
X_test = X_test[..., np.newaxis]

# CNN ëª¨ë¸ êµ¬ì„±
model = Sequential([
    Conv1D(256, kernel_size=5, activation='relu', input_shape=(175, 1)),
    Conv1D(128, kernel_size=5, activation='relu'),
    Dropout(0.1),
    MaxPooling1D(pool_size=5),
    Conv1D(128, kernel_size=5, activation='relu'),
    Conv1D(128, kernel_size=5, activation='relu'),
    Flatten(),
    Dense(10, activation='relu'),
    Dense(y_onehot.shape[1], activation='softmax')
])

model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# ì½œë°± ì •ì˜
checkpoint = ModelCheckpoint(
    filepath='CNN_model_result/best_model.h5',
    monitor='val_accuracy',
    save_best_only=True,
    mode='max',
    verbose=1
)

early_stop = EarlyStopping(
    monitor='val_accuracy',
    patience=10,
    mode='max',
    restore_best_weights=False,
    verbose=1
)

# í•™ìŠµ
model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.1,
    callbacks=[checkpoint, early_stop]
)

print("========================================================")

# ë§ˆì§€ë§‰ epoch ê¸°ì¤€ ëª¨ë¸ ì €ì¥
model.save("gender_cnn_model_2.h5")
print("âœ… ëª¨ë¸ì´ gender_cnn_model_2.h5 ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# í‰ê°€
loss, acc = model.evaluate(X_test, y_test)
print(f"âœ… [gender_cnn_model_2] í…ŒìŠ¤íŠ¸ ì •í™•ë„: {acc * 100:.2f}%")

# ì˜ˆì¸¡ ìˆ˜í–‰
y_pred_proba = model.predict(X_test)
y_pred = np.argmax(y_pred_proba, axis=1)
y_true = np.argmax(y_test, axis=1)

# í˜¼ë™ í–‰ë ¬
cm = confusion_matrix(y_true, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)
disp.plot(cmap='Blues')
plt.title("Confusion Matrix (gender_cnn_model_2)")
plt.savefig("gender_cnn_model_2_confusion_matrix.png", dpi=300)
plt.show()

print("\nğŸ“‹ Classification Report (gender_cnn_model_2):")
print(classification_report(y_true, y_pred, target_names=le.classes_))

print("========================================================")

# === best_model í‰ê°€ ===
best_model = load_model("CNN_model_result/best_model.h5")
best_loss, best_acc = best_model.evaluate(X_test, y_test)
print(f"\nğŸŒŸ [best_model.h5] ê¸°ì¤€ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {best_acc * 100:.2f}%")

best_pred = best_model.predict(X_test)
best_y_pred = np.argmax(best_pred, axis=1)

cm_best = confusion_matrix(y_true, best_y_pred)
disp_best = ConfusionMatrixDisplay(confusion_matrix=cm_best, display_labels=le.classes_)
disp_best.plot(cmap='Oranges')
plt.title("Confusion Matrix (best_model.h5)")
plt.savefig("best_model_confusion_matrix.png", dpi=300)
plt.show()

print("\nğŸ“‹ Classification Report (best_model.h5):")
print(classification_report(y_true, best_y_pred, target_names=le.classes_))

print("========================================================")

# ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ (wav_id + source í¬í•¨)
results_df = pd.DataFrame({
    "wav_id": wav_test,
    "source": src_test,
    "true_label": le.inverse_transform(y_true),
    "predicted_label": le.inverse_transform(best_y_pred),
    "correct": y_true == best_y_pred
})

results_df.to_csv("gender_classification_results.csv", index=False, encoding="utf-8-sig")
print("ğŸ“ ì˜ˆì¸¡ ê²°ê³¼ê°€ 'gender_classification_results.csv'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
